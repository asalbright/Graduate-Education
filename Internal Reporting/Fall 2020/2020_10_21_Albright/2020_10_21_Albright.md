Date: 10/21/2020    
Author: Andrew Albright    
Email: andrew.albright1@louisiana.edu    


# Discussion of Key Findings
Honestly, I have diverted much of my attention to the Crawfish Peeler and my classes (***cough*** 513) these past two weeks. We have seen good progress, I think, on the Peeler project as a whole so far this semester. The designs we have come up with as a team are looking promising. We are excited to finish assembly and start testing. And the report today went well.

In the limited time I have spent working on research related topics, I have found Google Colab will probably be a great platform to use. I have spent some time on their [Welcome to Colab](https://colab.research.google.com/notebooks/intro.ipynb#scrollTo=-Rh3-Vt9Nev9) page and have worked through some of the "More Resources" section. It is a intuitive platform which also is linked to my Google account for cloud storage of files. I have not found the best way to merge the files into GitHub however as it seems they need to be connected to the root directory on Git. I could just copy them directly to Git, but that seems unnecessary. Will discuss this with Gerald.

> ***JV*** I wonder if creating an alias/shortcut/symlink between your local GitHub folder and Google Drive would work. I haven't tried this, so please don't do it without looking around a bit first to see what others are doing. Syncing to GitHub is a really common thing, so I'd suspect that you can find a lot of solutions/suggestions without much trouble.

>***AA*** I have reached out to Gerald to see how he does it. I will look around as well.

# Current Difficulties

## Theoretical/Analytical Difficulties
### Understanding the Math 
I am still working through understanding a good bit of the math when reading through the RL papers. Though, since the last report, I have made some progress. Seems the more I read things that don't make sense, the more the pieces start to come together.

> ***JV*** I will typically add a note in my bibliography system that I need to revisit a paper because I didn't fully understand some part of it and set a reminder to do so in 2-3 weeks. *Very* often, on that second read, after having read other papers in the area, everything will click into place.

>***AA*** Yes as I mentioned some of the pieces are coming together the more I read. It helps that the technical way in which the equations are written are very similar across different researchers work. Per Dallas' suggestions I am going to be looking for videos to help illustrate the ideas better.

## Technical/Implementation Difficulties
### Time These Past Couple of Weeks
Simply spent a lot of time on the Crawfish Peeler presentation as well as my classes. Looking to catch up a bit on the reading and working these next two weeks.

# Team Activities
Brennon, Darcy and myself are still moving forward with the designs and concepts of the different sub-systems of the Crawfish Peeler. We completed getting the presentation material ready, and the presentation went smoothly.

1. Brennon - will continue to refine the Clamping designs
    * Has made some of the modifications to the subsystem
    * Current parts for the system have been printed and cut for testing
    * Waiting on material
    
2. Darcy - is waiting for 80-20 material to arrive to being assembly of Heat/tail Separator subsystem
    * Also working on the design of the Head/Tail Clasps (Clamps? anything but Paddles)
    
> ***JV*** We do need better name for those. Not sure what it is.

> ***AA*** My vote is for Head/Tail Clasps but Clamps works too. I think per that suggestion, Darcy went with Clamps.

1. Myself - has completed the designs for the first prototype of the Meat Extractor subsystem.
    * Material has been ordered and cut, awaiting other subsystems material to begin assembly
    * Further material has been ordered as well

2. We are all working on getting together an initial concept design for the tail cutting device
    * Plan to present these in the next Crawfish Peeling Meeting (10/26/2020)
    
# Papers
## High Level Reviews
1. AbdulKhader, S., Yin, H., Falco, P., & Kragic, D. (2020). Stability-Guaranteed Reinforcement Learning for Contact-rich Manipulation. IEEE Robotics and Automation Letters. https://doi.org/10.1109/LRA.2020.3028529
2. Buşoniu, L., de Bruin, T., Tolić, D., Kober, J., & Palunko, I. (2018, January 1). Reinforcement learning for control: Performance, stability, and deep approximators. Annual Reviews in Control. Elsevier Ltd. https://doi.org/10.1016/j.arcontrol.2018.09.005
3. Da, X., Xie, Z., Hoeller, D., Boots, B., Anandkumar, A., Zhu, Y., … Garg, A. (2020). Learning a Contact-Adaptive Controller for Robust, Efficient Legged Locomotion. Retrieved from http://arxiv.org/abs/2009.10019
4. Srinivas, A., Laskin, M., & Abbeel, P. (2020). CURL: Contrastive Unsupervised Representations for Reinforcement Learning. Retrieved from http://arxiv.org/abs/2004.04136
5. Robine, J., Uelwer, T., & Harmeling, S. (2020). Discrete Latent Space World Models for Reinforcement Learning. Retrieved from http://arxiv.org/abs/2010.05767
6. Jomaa, H. S., Grabocka, J., & Schmidt-Thieme, L. (2019). Hyp-RL : Hyperparameter Optimization by Reinforcement Learning. Retrieved from http://arxiv.org/abs/1906.11527
7. Nair, A., Dalal, M., Gupta, A., & Levine, S. (2020). Accelerating Online Reinforcement Learning with Offline Datasets. Retrieved from http://arxiv.org/abs/2006.09359
8. Laskin, M., Lee, K., Stooke, A., Pinto, L., Abbeel, P., & Srinivas, A. (2020). Reinforcement Learning with Augmented Data. Retrieved from http://arxiv.org/abs/2004.14990
9. Zhang, L. M., Plappert, M., & Zaremba, W. (2020). Predicting Sim-to-Real Transfer with Probabilistic Dynamics Models. Retrieved from http://arxiv.org/abs/2009.12864
10. Berkenkamp, F., Turchetta, M., Schoellig, A. P., & Krause, A. (2017). Safe model-based reinforcement learning with stability guarantees. In Advances in Neural Information Processing Systems (Vol. 2017-December, pp. 909–919). Neural information processing systems foundation.
11. Stooke, A., Lee, K., Abbeel, P., & Laskin, M. (2020). Decoupling Representation Learning from Reinforcement Learning. Retrieved from http://arxiv.org/abs/2009.08319
12. Reda, D., Tao, T., & van de Panne, M. (2020). Learning to Locomote: Understanding How Environment Design Matters for Deep Reinforcement Learning. https://doi.org/10.1145/3424636.3426907
13. Lu, J., Richter, F., & Yip, M. (2020). Robust Keypoint Detection and Pose Estimation of Robot Manipulators with Self-Occlusions via Sim-to-Real Transfer. Retrieved from http://arxiv.org/abs/2010.08054
14. Buchli, J., Stulp, F., Theodorou, E., & Schaal, S. (2011). Learning variable impedance control. In International Journal of Robotics Research (Vol. 30, pp. 820–833). https://doi.org/10.1177/0278364911402527

## Detailed Reviews

### AbdulKhader, S., Yin, H., Falco, P., & Kragic, D. (2020). Stability-Guaranteed Reinforcement Learning for Contact-rich Manipulation. IEEE Robotics and Automation Letters. https://doi.org/10.1109/LRA.2020.3028529

### Summary
Explores the development of an RL algorithm which excels in, but is not limited to, "contact rich" environments. Perhaps more important than it performing well in these types of environments is its employment of "*all-the-time-stability*". That is stability no matter the action explored.

### Main Contribution to Relationship Field
Development of an algorithm which other algorithms which aims to achieve seeing stability through any action taken by a system/agent.

### Relevance to Current Research
This, I think is getting into more of what I want to learn about specifically.

> ***JV*** Sounds good. I think both the crawfish peeler and our walking robots could serve as applications examples for work like this. Having the same algorithms working on such dissimilar systems would be a *great* result.

There is a lot of general overhead knowledge to both fields in control and RL and I am looking to try and zone into some things that I will directly use and keep the rest stored for later looks when I have more time.

> ***JV*** We need to work on transitioning to getting more results for you, to move out of the foundation building being the main place of attention to focusing attention on generating new knowledge and results supporting it. I really think a lot of the concepts will click into place once you start working on applying them to your work. 

> ***AA*** I agree with this 100%. Reading up on things just isn't rewarding enough to give me the drive either. I need a problem to solve to really have a purpose to go out and find the solution.


### Reda, D., Tao, T., & van de Panne, M. (2020). Learning to Locomote: Understanding How Environment Design Matters for Deep Reinforcement Learning. https://doi.org/10.1145/3424636.3426907

### Summary
Paper illustrates why environment design matters for designing/deploying successful RL applications. Specific environmental factors discussed are "state representations, initial state distributions, reward structure, control frequency, episode termination procedures, curriculum usage, the action space, and the torque limits" Utilizes TD3 RL algorithm.

### Main Contribution to Relationship Field
Explores the advantages of changes to the environment which the agent learns. Discovers that changes to some factors are more effective than others and in most instances are effective in some tasks more than others. 

### Relevance to Current Research
For me this is a first read on the topic of optimization training of an agent (in this case a TP3 agent). In this case the optimization is done, or attempted to be done, employing changes to the environment in which the agent learns. If anything this is a good source of work for seeking a place where I want to follow a path.
 
 
### Da, X., Xie, Z., Hoeller, D., Boots, B., Anandkumar, A., Zhu, Y., … Garg, A. (2020). Learning a Contact-Adaptive Controller for Robust, Efficient Legged Locomotion. Retrieved from http://arxiv.org/abs/2009.10019

### Summary
Develop work on a RL trained high level controller to assist in defining a control strategy for quadrupedal movement type robots. Utilizes a double Q-function type algorithm and a DQN type training strategy. Shows that the trained controller develop contact sequences not seen before by MPC or learned-controllers. Shows the controller is capable producing movements which are 85% more efficient than alternative routes. 

### Main Contribution to Relationship Field
Shows the relevance of RL in the field of locomotive type robots both in simulation and on actual hardware. Shows that utilizing a system in which a high-level controller is trained using RL can produce a system which can be significantly more energy efficient in its movements as well as deploying movements not seen in controllers such as MPC's.

### Relevance to Current Research
Really this was interesting to me beyond anything else. It is relevant in that the ideas here are related to deploying RL in a controls setting. This is surely related to what I want to study, but perhaps a bit beyond the scope of a masters. Still, I think its pretty dope!


> ***JV*** Please remember that we want 2-3 detailed reads per *week*, not per report.
> ***AA*** Yes sir. Fell behind these past couple of weeks.

## Future Reading
### Types of papers I plan to read in the next two weeks:
* I will be looking into reading more about the specific algorithms that are used in robotics. As well as looking for examples of people implementing these in simulation and hopefully on actual hardware, too.

> ***JV*** What types of algorithms? 

> ***AA*** Based on my reading, ones which excel in continuous action spaces. Ones which are opt for robotics type systems. I know there are a lot of options out there but I am not at the point where I can say I know I will be using X, Y and Z algorithms to do my research. However there are some that I think (not know) that I wont be using. 

### What I am aiming to achieve from reading these papers: 
* Grow, and more importantly, guide my understanding towards ideas and developments that are relevant to what I want to learn about and contribute to.

### Why I am looking to achieve that:
* So that I can start getting addicted to the work I am doing here. Reading papers about "foundational" knowledge is important but not particularly fun, I want to start following a path that leads to me doing testing on things I am directly interested in.

> ***JV*** I agree.     
> Copied from above... We need to work on transitioning to getting more results for you, to move out of the foundation building being the main place of attention to focusing attention on generating new knowledge and results supporting it. I really think a lot of the concepts will click into place once you start working on applying them to your work. 

>***AA*** ^^

# Plan for the Next Two Weeks
At a glance, work on the Crawfish Peeler designs (specifically the Tail Cutting subsystem), and continue learning how to use Google Colab to better my understanding of RL and Python in general. Also read more.

## Ideas Looking Forward

### Crawfish Peeler Project
We are all currently putting together some ideas for the Tail Cutting subsystem which is lagging behind the rest of the design. We are waiting for material to arrive as well so we can form some ideas about the designs we have related to the testing we do. I have had some ideas (or revelations rather) relating to the design of the subsystem I have worked on. Materials have been ordered to explore these ideas.

### Robotics Research
Since my introduction to RL (new topic to me since I arrived here) my views in what I want to do have changed since I started. I've become more interested in the topic of RL, and the more I read, the more I want to incorporate it into my contribution to the field. I want to get some things into simulation so I can start realizing the potential that exists and would like your help getting there.

> ***JV*** Let's set a time for a longer discussion sometime next week (week of 11/2). Please email me a few time ranges that you could meet.

> ***AA*** I will email you my schedule next week.

I have not spent very much time on my personal work since the last report as I have been focusing on classes and the Crawfish Peeler designs/presentation. Since the presentation has gone well, and we have a bit of "breathing room" I will be looking to get back to devoting time to this side of my work.

## Current Next Steps

### Crawfish Peeler Project
Have a concept design for the Tail Cutting subsystem finalized for the team to move forward with.

### Robotics Research
Since last report, get back into spending time in this side of my research. I have not been able to make the progress I had hoped for since my last report as I prioritized other things.

## Expectations for Next Report (10/21/2020)
1. Worked through *more* tutorial examples in Google Colab and synced that code to GitHub.
    * Simulate some "benchmark" examples such as the inverted pendulum
    * Discuss with Gerald how he connected (if he connected) his GitHub to Google Colab
      * I have just been storing the documents on my Google cloud, since that is where they are sorted by Google

2. Learn how to model a system utilizing Python
    * Didn't have time to do this yet. However it remains on my list as I think it will very beneficial

3. Re-write some of the RL algorithms I think I might be using to do some work
    * This is also still on my list, as again I think it will be beneficial

4. Work on writing this throughout the two weeks instead of on the last two days
    * Well, I started off strong... for a few days. Then diverted my attention elsewhere. I'll get back to it though.

## Current Schedule Outlook
* 10/23 - Crawfish Peeling Team Check-In
* 10/26 - Crawfish Peeling Meeting
* 10/28 - Crawfish Bi-Weekly Report Due
* 10/30 - Crawfish Peeling Team Check-In
* 10/30 - My Research Report for team CRAW LAB
* 11/02 - Crawfish Peeling Meeting
* 11/04 - Next Report Due

# Long-term planning

## Upcoming Paper Deadlines
Spring conference season. Thinking about trying to have some work done towards the RL side of things. 

## Administrative Deadlines
### Crawfish Peeler
* No immediate deadlines. However, we are thinking forward knowing the next report for the Board will be the first quarter of next year.

### Research
* ***Deadline*** to turn in completed, edited thesis to graduate school
  - Two weeks before ***Deadline***: Defended thesis to graduate school for edits
  - Two weeks before ***Defending thesis to the graduate school***: Defend thesis in front of committee
  - Two weeks before ***Defending thesis to the committee***: Submit completed thesis to committee
  - One month before ***Submiting thesis to committee***: submit completed thesis to Dr. Vaughan to edit and make additions as necessary
  * Ideally have the "Mostly Completed" thesis finished 2.5 months before it is to be submitted to the graduate school